{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Импортируйте библиотеки pandas и numpy.\n",
    "Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn.\n",
    "Создайте датафреймы X и y из этих данных.\n",
    "\n",
    "Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) \n",
    "с помощью функции train_test_split так, чтобы размер тестовой выборки \n",
    "составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42.\n",
    "\n",
    "Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из \n",
    "модуля sklearn.linear_model. Используйте все признаки.\n",
    "\n",
    "Обучите модель на тренировочных данных и сделайте предсказание на тестовых.\n",
    "Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename'])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 66
    }
   ],
   "source": [
    "boston.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "data = boston.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "target = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "feature_names = boston.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7')"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 70
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "         CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS   RAD    TAX  \\\n0     0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900   1.0  296.0   \n1     0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671   2.0  242.0   \n2     0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671   2.0  242.0   \n3     0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622   3.0  222.0   \n4     0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622   3.0  222.0   \n5     0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622   3.0  222.0   \n6     0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605   5.0  311.0   \n7     0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505   5.0  311.0   \n8     0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821   5.0  311.0   \n9     0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921   5.0  311.0   \n10    0.22489  12.5   7.87   0.0  0.524  6.377   94.3  6.3467   5.0  311.0   \n11    0.11747  12.5   7.87   0.0  0.524  6.009   82.9  6.2267   5.0  311.0   \n12    0.09378  12.5   7.87   0.0  0.524  5.889   39.0  5.4509   5.0  311.0   \n13    0.62976   0.0   8.14   0.0  0.538  5.949   61.8  4.7075   4.0  307.0   \n14    0.63796   0.0   8.14   0.0  0.538  6.096   84.5  4.4619   4.0  307.0   \n15    0.62739   0.0   8.14   0.0  0.538  5.834   56.5  4.4986   4.0  307.0   \n16    1.05393   0.0   8.14   0.0  0.538  5.935   29.3  4.4986   4.0  307.0   \n17    0.78420   0.0   8.14   0.0  0.538  5.990   81.7  4.2579   4.0  307.0   \n18    0.80271   0.0   8.14   0.0  0.538  5.456   36.6  3.7965   4.0  307.0   \n19    0.72580   0.0   8.14   0.0  0.538  5.727   69.5  3.7965   4.0  307.0   \n20    1.25179   0.0   8.14   0.0  0.538  5.570   98.1  3.7979   4.0  307.0   \n21    0.85204   0.0   8.14   0.0  0.538  5.965   89.2  4.0123   4.0  307.0   \n22    1.23247   0.0   8.14   0.0  0.538  6.142   91.7  3.9769   4.0  307.0   \n23    0.98843   0.0   8.14   0.0  0.538  5.813  100.0  4.0952   4.0  307.0   \n24    0.75026   0.0   8.14   0.0  0.538  5.924   94.1  4.3996   4.0  307.0   \n25    0.84054   0.0   8.14   0.0  0.538  5.599   85.7  4.4546   4.0  307.0   \n26    0.67191   0.0   8.14   0.0  0.538  5.813   90.3  4.6820   4.0  307.0   \n27    0.95577   0.0   8.14   0.0  0.538  6.047   88.8  4.4534   4.0  307.0   \n28    0.77299   0.0   8.14   0.0  0.538  6.495   94.4  4.4547   4.0  307.0   \n29    1.00245   0.0   8.14   0.0  0.538  6.674   87.3  4.2390   4.0  307.0   \n..        ...   ...    ...   ...    ...    ...    ...     ...   ...    ...   \n476   4.87141   0.0  18.10   0.0  0.614  6.484   93.6  2.3053  24.0  666.0   \n477  15.02340   0.0  18.10   0.0  0.614  5.304   97.3  2.1007  24.0  666.0   \n478  10.23300   0.0  18.10   0.0  0.614  6.185   96.7  2.1705  24.0  666.0   \n479  14.33370   0.0  18.10   0.0  0.614  6.229   88.0  1.9512  24.0  666.0   \n480   5.82401   0.0  18.10   0.0  0.532  6.242   64.7  3.4242  24.0  666.0   \n481   5.70818   0.0  18.10   0.0  0.532  6.750   74.9  3.3317  24.0  666.0   \n482   5.73116   0.0  18.10   0.0  0.532  7.061   77.0  3.4106  24.0  666.0   \n483   2.81838   0.0  18.10   0.0  0.532  5.762   40.3  4.0983  24.0  666.0   \n484   2.37857   0.0  18.10   0.0  0.583  5.871   41.9  3.7240  24.0  666.0   \n485   3.67367   0.0  18.10   0.0  0.583  6.312   51.9  3.9917  24.0  666.0   \n486   5.69175   0.0  18.10   0.0  0.583  6.114   79.8  3.5459  24.0  666.0   \n487   4.83567   0.0  18.10   0.0  0.583  5.905   53.2  3.1523  24.0  666.0   \n488   0.15086   0.0  27.74   0.0  0.609  5.454   92.7  1.8209   4.0  711.0   \n489   0.18337   0.0  27.74   0.0  0.609  5.414   98.3  1.7554   4.0  711.0   \n490   0.20746   0.0  27.74   0.0  0.609  5.093   98.0  1.8226   4.0  711.0   \n491   0.10574   0.0  27.74   0.0  0.609  5.983   98.8  1.8681   4.0  711.0   \n492   0.11132   0.0  27.74   0.0  0.609  5.983   83.5  2.1099   4.0  711.0   \n493   0.17331   0.0   9.69   0.0  0.585  5.707   54.0  2.3817   6.0  391.0   \n494   0.27957   0.0   9.69   0.0  0.585  5.926   42.6  2.3817   6.0  391.0   \n495   0.17899   0.0   9.69   0.0  0.585  5.670   28.8  2.7986   6.0  391.0   \n496   0.28960   0.0   9.69   0.0  0.585  5.390   72.9  2.7986   6.0  391.0   \n497   0.26838   0.0   9.69   0.0  0.585  5.794   70.6  2.8927   6.0  391.0   \n498   0.23912   0.0   9.69   0.0  0.585  6.019   65.3  2.4091   6.0  391.0   \n499   0.17783   0.0   9.69   0.0  0.585  5.569   73.5  2.3999   6.0  391.0   \n500   0.22438   0.0   9.69   0.0  0.585  6.027   79.7  2.4982   6.0  391.0   \n501   0.06263   0.0  11.93   0.0  0.573  6.593   69.1  2.4786   1.0  273.0   \n502   0.04527   0.0  11.93   0.0  0.573  6.120   76.7  2.2875   1.0  273.0   \n503   0.06076   0.0  11.93   0.0  0.573  6.976   91.0  2.1675   1.0  273.0   \n504   0.10959   0.0  11.93   0.0  0.573  6.794   89.3  2.3889   1.0  273.0   \n505   0.04741   0.0  11.93   0.0  0.573  6.030   80.8  2.5050   1.0  273.0   \n\n     PTRATIO       B  LSTAT  \n0       15.3  396.90   4.98  \n1       17.8  396.90   9.14  \n2       17.8  392.83   4.03  \n3       18.7  394.63   2.94  \n4       18.7  396.90   5.33  \n5       18.7  394.12   5.21  \n6       15.2  395.60  12.43  \n7       15.2  396.90  19.15  \n8       15.2  386.63  29.93  \n9       15.2  386.71  17.10  \n10      15.2  392.52  20.45  \n11      15.2  396.90  13.27  \n12      15.2  390.50  15.71  \n13      21.0  396.90   8.26  \n14      21.0  380.02  10.26  \n15      21.0  395.62   8.47  \n16      21.0  386.85   6.58  \n17      21.0  386.75  14.67  \n18      21.0  288.99  11.69  \n19      21.0  390.95  11.28  \n20      21.0  376.57  21.02  \n21      21.0  392.53  13.83  \n22      21.0  396.90  18.72  \n23      21.0  394.54  19.88  \n24      21.0  394.33  16.30  \n25      21.0  303.42  16.51  \n26      21.0  376.88  14.81  \n27      21.0  306.38  17.28  \n28      21.0  387.94  12.80  \n29      21.0  380.23  11.98  \n..       ...     ...    ...  \n476     20.2  396.21  18.68  \n477     20.2  349.48  24.91  \n478     20.2  379.70  18.03  \n479     20.2  383.32  13.11  \n480     20.2  396.90  10.74  \n481     20.2  393.07   7.74  \n482     20.2  395.28   7.01  \n483     20.2  392.92  10.42  \n484     20.2  370.73  13.34  \n485     20.2  388.62  10.58  \n486     20.2  392.68  14.98  \n487     20.2  388.22  11.45  \n488     20.1  395.09  18.06  \n489     20.1  344.05  23.97  \n490     20.1  318.43  29.68  \n491     20.1  390.11  18.07  \n492     20.1  396.90  13.35  \n493     19.2  396.90  12.01  \n494     19.2  396.90  13.59  \n495     19.2  393.29  17.60  \n496     19.2  396.90  21.14  \n497     19.2  396.90  14.10  \n498     19.2  396.90  12.92  \n499     19.2  395.77  15.10  \n500     19.2  396.90  14.33  \n501     21.0  391.99   9.67  \n502     21.0  396.90   9.08  \n503     21.0  396.90   5.64  \n504     21.0  393.45   6.48  \n505     21.0  396.90   7.88  \n\n[506 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>CRIM</th>\n      <th>ZN</th>\n      <th>INDUS</th>\n      <th>CHAS</th>\n      <th>NOX</th>\n      <th>RM</th>\n      <th>AGE</th>\n      <th>DIS</th>\n      <th>RAD</th>\n      <th>TAX</th>\n      <th>PTRATIO</th>\n      <th>B</th>\n      <th>LSTAT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00632</td>\n      <td>18.0</td>\n      <td>2.31</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>6.575</td>\n      <td>65.2</td>\n      <td>4.0900</td>\n      <td>1.0</td>\n      <td>296.0</td>\n      <td>15.3</td>\n      <td>396.90</td>\n      <td>4.98</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.02731</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0.0</td>\n      <td>0.469</td>\n      <td>6.421</td>\n      <td>78.9</td>\n      <td>4.9671</td>\n      <td>2.0</td>\n      <td>242.0</td>\n      <td>17.8</td>\n      <td>396.90</td>\n      <td>9.14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.02729</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0.0</td>\n      <td>0.469</td>\n      <td>7.185</td>\n      <td>61.1</td>\n      <td>4.9671</td>\n      <td>2.0</td>\n      <td>242.0</td>\n      <td>17.8</td>\n      <td>392.83</td>\n      <td>4.03</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.03237</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0.0</td>\n      <td>0.458</td>\n      <td>6.998</td>\n      <td>45.8</td>\n      <td>6.0622</td>\n      <td>3.0</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>394.63</td>\n      <td>2.94</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.06905</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0.0</td>\n      <td>0.458</td>\n      <td>7.147</td>\n      <td>54.2</td>\n      <td>6.0622</td>\n      <td>3.0</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>396.90</td>\n      <td>5.33</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.02985</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0.0</td>\n      <td>0.458</td>\n      <td>6.430</td>\n      <td>58.7</td>\n      <td>6.0622</td>\n      <td>3.0</td>\n      <td>222.0</td>\n      <td>18.7</td>\n      <td>394.12</td>\n      <td>5.21</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.08829</td>\n      <td>12.5</td>\n      <td>7.87</td>\n      <td>0.0</td>\n      <td>0.524</td>\n      <td>6.012</td>\n      <td>66.6</td>\n      <td>5.5605</td>\n      <td>5.0</td>\n      <td>311.0</td>\n      <td>15.2</td>\n      <td>395.60</td>\n      <td>12.43</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.14455</td>\n      <td>12.5</td>\n      <td>7.87</td>\n      <td>0.0</td>\n      <td>0.524</td>\n      <td>6.172</td>\n      <td>96.1</td>\n      <td>5.9505</td>\n      <td>5.0</td>\n      <td>311.0</td>\n      <td>15.2</td>\n      <td>396.90</td>\n      <td>19.15</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.21124</td>\n      <td>12.5</td>\n      <td>7.87</td>\n      <td>0.0</td>\n      <td>0.524</td>\n      <td>5.631</td>\n      <td>100.0</td>\n      <td>6.0821</td>\n      <td>5.0</td>\n      <td>311.0</td>\n      <td>15.2</td>\n      <td>386.63</td>\n      <td>29.93</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.17004</td>\n      <td>12.5</td>\n      <td>7.87</td>\n      <td>0.0</td>\n      <td>0.524</td>\n      <td>6.004</td>\n      <td>85.9</td>\n      <td>6.5921</td>\n      <td>5.0</td>\n      <td>311.0</td>\n      <td>15.2</td>\n      <td>386.71</td>\n      <td>17.10</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.22489</td>\n      <td>12.5</td>\n      <td>7.87</td>\n      <td>0.0</td>\n      <td>0.524</td>\n      <td>6.377</td>\n      <td>94.3</td>\n      <td>6.3467</td>\n      <td>5.0</td>\n      <td>311.0</td>\n      <td>15.2</td>\n      <td>392.52</td>\n      <td>20.45</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.11747</td>\n      <td>12.5</td>\n      <td>7.87</td>\n      <td>0.0</td>\n      <td>0.524</td>\n      <td>6.009</td>\n      <td>82.9</td>\n      <td>6.2267</td>\n      <td>5.0</td>\n      <td>311.0</td>\n      <td>15.2</td>\n      <td>396.90</td>\n      <td>13.27</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.09378</td>\n      <td>12.5</td>\n      <td>7.87</td>\n      <td>0.0</td>\n      <td>0.524</td>\n      <td>5.889</td>\n      <td>39.0</td>\n      <td>5.4509</td>\n      <td>5.0</td>\n      <td>311.0</td>\n      <td>15.2</td>\n      <td>390.50</td>\n      <td>15.71</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>0.62976</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>5.949</td>\n      <td>61.8</td>\n      <td>4.7075</td>\n      <td>4.0</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>396.90</td>\n      <td>8.26</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.63796</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>6.096</td>\n      <td>84.5</td>\n      <td>4.4619</td>\n      <td>4.0</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>380.02</td>\n      <td>10.26</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>0.62739</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>5.834</td>\n      <td>56.5</td>\n      <td>4.4986</td>\n      <td>4.0</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>395.62</td>\n      <td>8.47</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1.05393</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>5.935</td>\n      <td>29.3</td>\n      <td>4.4986</td>\n      <td>4.0</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>386.85</td>\n      <td>6.58</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>0.78420</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>5.990</td>\n      <td>81.7</td>\n      <td>4.2579</td>\n      <td>4.0</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>386.75</td>\n      <td>14.67</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>0.80271</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>5.456</td>\n      <td>36.6</td>\n      <td>3.7965</td>\n      <td>4.0</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>288.99</td>\n      <td>11.69</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>0.72580</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>5.727</td>\n      <td>69.5</td>\n      <td>3.7965</td>\n      <td>4.0</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>390.95</td>\n      <td>11.28</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1.25179</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>5.570</td>\n      <td>98.1</td>\n      <td>3.7979</td>\n      <td>4.0</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>376.57</td>\n      <td>21.02</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>0.85204</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>5.965</td>\n      <td>89.2</td>\n      <td>4.0123</td>\n      <td>4.0</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>392.53</td>\n      <td>13.83</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>1.23247</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>6.142</td>\n      <td>91.7</td>\n      <td>3.9769</td>\n      <td>4.0</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>396.90</td>\n      <td>18.72</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>0.98843</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>5.813</td>\n      <td>100.0</td>\n      <td>4.0952</td>\n      <td>4.0</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>394.54</td>\n      <td>19.88</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>0.75026</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>5.924</td>\n      <td>94.1</td>\n      <td>4.3996</td>\n      <td>4.0</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>394.33</td>\n      <td>16.30</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>0.84054</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>5.599</td>\n      <td>85.7</td>\n      <td>4.4546</td>\n      <td>4.0</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>303.42</td>\n      <td>16.51</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>0.67191</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>5.813</td>\n      <td>90.3</td>\n      <td>4.6820</td>\n      <td>4.0</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>376.88</td>\n      <td>14.81</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>0.95577</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>6.047</td>\n      <td>88.8</td>\n      <td>4.4534</td>\n      <td>4.0</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>306.38</td>\n      <td>17.28</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>0.77299</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>6.495</td>\n      <td>94.4</td>\n      <td>4.4547</td>\n      <td>4.0</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>387.94</td>\n      <td>12.80</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>1.00245</td>\n      <td>0.0</td>\n      <td>8.14</td>\n      <td>0.0</td>\n      <td>0.538</td>\n      <td>6.674</td>\n      <td>87.3</td>\n      <td>4.2390</td>\n      <td>4.0</td>\n      <td>307.0</td>\n      <td>21.0</td>\n      <td>380.23</td>\n      <td>11.98</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>476</th>\n      <td>4.87141</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0.0</td>\n      <td>0.614</td>\n      <td>6.484</td>\n      <td>93.6</td>\n      <td>2.3053</td>\n      <td>24.0</td>\n      <td>666.0</td>\n      <td>20.2</td>\n      <td>396.21</td>\n      <td>18.68</td>\n    </tr>\n    <tr>\n      <th>477</th>\n      <td>15.02340</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0.0</td>\n      <td>0.614</td>\n      <td>5.304</td>\n      <td>97.3</td>\n      <td>2.1007</td>\n      <td>24.0</td>\n      <td>666.0</td>\n      <td>20.2</td>\n      <td>349.48</td>\n      <td>24.91</td>\n    </tr>\n    <tr>\n      <th>478</th>\n      <td>10.23300</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0.0</td>\n      <td>0.614</td>\n      <td>6.185</td>\n      <td>96.7</td>\n      <td>2.1705</td>\n      <td>24.0</td>\n      <td>666.0</td>\n      <td>20.2</td>\n      <td>379.70</td>\n      <td>18.03</td>\n    </tr>\n    <tr>\n      <th>479</th>\n      <td>14.33370</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0.0</td>\n      <td>0.614</td>\n      <td>6.229</td>\n      <td>88.0</td>\n      <td>1.9512</td>\n      <td>24.0</td>\n      <td>666.0</td>\n      <td>20.2</td>\n      <td>383.32</td>\n      <td>13.11</td>\n    </tr>\n    <tr>\n      <th>480</th>\n      <td>5.82401</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0.0</td>\n      <td>0.532</td>\n      <td>6.242</td>\n      <td>64.7</td>\n      <td>3.4242</td>\n      <td>24.0</td>\n      <td>666.0</td>\n      <td>20.2</td>\n      <td>396.90</td>\n      <td>10.74</td>\n    </tr>\n    <tr>\n      <th>481</th>\n      <td>5.70818</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0.0</td>\n      <td>0.532</td>\n      <td>6.750</td>\n      <td>74.9</td>\n      <td>3.3317</td>\n      <td>24.0</td>\n      <td>666.0</td>\n      <td>20.2</td>\n      <td>393.07</td>\n      <td>7.74</td>\n    </tr>\n    <tr>\n      <th>482</th>\n      <td>5.73116</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0.0</td>\n      <td>0.532</td>\n      <td>7.061</td>\n      <td>77.0</td>\n      <td>3.4106</td>\n      <td>24.0</td>\n      <td>666.0</td>\n      <td>20.2</td>\n      <td>395.28</td>\n      <td>7.01</td>\n    </tr>\n    <tr>\n      <th>483</th>\n      <td>2.81838</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0.0</td>\n      <td>0.532</td>\n      <td>5.762</td>\n      <td>40.3</td>\n      <td>4.0983</td>\n      <td>24.0</td>\n      <td>666.0</td>\n      <td>20.2</td>\n      <td>392.92</td>\n      <td>10.42</td>\n    </tr>\n    <tr>\n      <th>484</th>\n      <td>2.37857</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0.0</td>\n      <td>0.583</td>\n      <td>5.871</td>\n      <td>41.9</td>\n      <td>3.7240</td>\n      <td>24.0</td>\n      <td>666.0</td>\n      <td>20.2</td>\n      <td>370.73</td>\n      <td>13.34</td>\n    </tr>\n    <tr>\n      <th>485</th>\n      <td>3.67367</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0.0</td>\n      <td>0.583</td>\n      <td>6.312</td>\n      <td>51.9</td>\n      <td>3.9917</td>\n      <td>24.0</td>\n      <td>666.0</td>\n      <td>20.2</td>\n      <td>388.62</td>\n      <td>10.58</td>\n    </tr>\n    <tr>\n      <th>486</th>\n      <td>5.69175</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0.0</td>\n      <td>0.583</td>\n      <td>6.114</td>\n      <td>79.8</td>\n      <td>3.5459</td>\n      <td>24.0</td>\n      <td>666.0</td>\n      <td>20.2</td>\n      <td>392.68</td>\n      <td>14.98</td>\n    </tr>\n    <tr>\n      <th>487</th>\n      <td>4.83567</td>\n      <td>0.0</td>\n      <td>18.10</td>\n      <td>0.0</td>\n      <td>0.583</td>\n      <td>5.905</td>\n      <td>53.2</td>\n      <td>3.1523</td>\n      <td>24.0</td>\n      <td>666.0</td>\n      <td>20.2</td>\n      <td>388.22</td>\n      <td>11.45</td>\n    </tr>\n    <tr>\n      <th>488</th>\n      <td>0.15086</td>\n      <td>0.0</td>\n      <td>27.74</td>\n      <td>0.0</td>\n      <td>0.609</td>\n      <td>5.454</td>\n      <td>92.7</td>\n      <td>1.8209</td>\n      <td>4.0</td>\n      <td>711.0</td>\n      <td>20.1</td>\n      <td>395.09</td>\n      <td>18.06</td>\n    </tr>\n    <tr>\n      <th>489</th>\n      <td>0.18337</td>\n      <td>0.0</td>\n      <td>27.74</td>\n      <td>0.0</td>\n      <td>0.609</td>\n      <td>5.414</td>\n      <td>98.3</td>\n      <td>1.7554</td>\n      <td>4.0</td>\n      <td>711.0</td>\n      <td>20.1</td>\n      <td>344.05</td>\n      <td>23.97</td>\n    </tr>\n    <tr>\n      <th>490</th>\n      <td>0.20746</td>\n      <td>0.0</td>\n      <td>27.74</td>\n      <td>0.0</td>\n      <td>0.609</td>\n      <td>5.093</td>\n      <td>98.0</td>\n      <td>1.8226</td>\n      <td>4.0</td>\n      <td>711.0</td>\n      <td>20.1</td>\n      <td>318.43</td>\n      <td>29.68</td>\n    </tr>\n    <tr>\n      <th>491</th>\n      <td>0.10574</td>\n      <td>0.0</td>\n      <td>27.74</td>\n      <td>0.0</td>\n      <td>0.609</td>\n      <td>5.983</td>\n      <td>98.8</td>\n      <td>1.8681</td>\n      <td>4.0</td>\n      <td>711.0</td>\n      <td>20.1</td>\n      <td>390.11</td>\n      <td>18.07</td>\n    </tr>\n    <tr>\n      <th>492</th>\n      <td>0.11132</td>\n      <td>0.0</td>\n      <td>27.74</td>\n      <td>0.0</td>\n      <td>0.609</td>\n      <td>5.983</td>\n      <td>83.5</td>\n      <td>2.1099</td>\n      <td>4.0</td>\n      <td>711.0</td>\n      <td>20.1</td>\n      <td>396.90</td>\n      <td>13.35</td>\n    </tr>\n    <tr>\n      <th>493</th>\n      <td>0.17331</td>\n      <td>0.0</td>\n      <td>9.69</td>\n      <td>0.0</td>\n      <td>0.585</td>\n      <td>5.707</td>\n      <td>54.0</td>\n      <td>2.3817</td>\n      <td>6.0</td>\n      <td>391.0</td>\n      <td>19.2</td>\n      <td>396.90</td>\n      <td>12.01</td>\n    </tr>\n    <tr>\n      <th>494</th>\n      <td>0.27957</td>\n      <td>0.0</td>\n      <td>9.69</td>\n      <td>0.0</td>\n      <td>0.585</td>\n      <td>5.926</td>\n      <td>42.6</td>\n      <td>2.3817</td>\n      <td>6.0</td>\n      <td>391.0</td>\n      <td>19.2</td>\n      <td>396.90</td>\n      <td>13.59</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>0.17899</td>\n      <td>0.0</td>\n      <td>9.69</td>\n      <td>0.0</td>\n      <td>0.585</td>\n      <td>5.670</td>\n      <td>28.8</td>\n      <td>2.7986</td>\n      <td>6.0</td>\n      <td>391.0</td>\n      <td>19.2</td>\n      <td>393.29</td>\n      <td>17.60</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>0.28960</td>\n      <td>0.0</td>\n      <td>9.69</td>\n      <td>0.0</td>\n      <td>0.585</td>\n      <td>5.390</td>\n      <td>72.9</td>\n      <td>2.7986</td>\n      <td>6.0</td>\n      <td>391.0</td>\n      <td>19.2</td>\n      <td>396.90</td>\n      <td>21.14</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>0.26838</td>\n      <td>0.0</td>\n      <td>9.69</td>\n      <td>0.0</td>\n      <td>0.585</td>\n      <td>5.794</td>\n      <td>70.6</td>\n      <td>2.8927</td>\n      <td>6.0</td>\n      <td>391.0</td>\n      <td>19.2</td>\n      <td>396.90</td>\n      <td>14.10</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>0.23912</td>\n      <td>0.0</td>\n      <td>9.69</td>\n      <td>0.0</td>\n      <td>0.585</td>\n      <td>6.019</td>\n      <td>65.3</td>\n      <td>2.4091</td>\n      <td>6.0</td>\n      <td>391.0</td>\n      <td>19.2</td>\n      <td>396.90</td>\n      <td>12.92</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>0.17783</td>\n      <td>0.0</td>\n      <td>9.69</td>\n      <td>0.0</td>\n      <td>0.585</td>\n      <td>5.569</td>\n      <td>73.5</td>\n      <td>2.3999</td>\n      <td>6.0</td>\n      <td>391.0</td>\n      <td>19.2</td>\n      <td>395.77</td>\n      <td>15.10</td>\n    </tr>\n    <tr>\n      <th>500</th>\n      <td>0.22438</td>\n      <td>0.0</td>\n      <td>9.69</td>\n      <td>0.0</td>\n      <td>0.585</td>\n      <td>6.027</td>\n      <td>79.7</td>\n      <td>2.4982</td>\n      <td>6.0</td>\n      <td>391.0</td>\n      <td>19.2</td>\n      <td>396.90</td>\n      <td>14.33</td>\n    </tr>\n    <tr>\n      <th>501</th>\n      <td>0.06263</td>\n      <td>0.0</td>\n      <td>11.93</td>\n      <td>0.0</td>\n      <td>0.573</td>\n      <td>6.593</td>\n      <td>69.1</td>\n      <td>2.4786</td>\n      <td>1.0</td>\n      <td>273.0</td>\n      <td>21.0</td>\n      <td>391.99</td>\n      <td>9.67</td>\n    </tr>\n    <tr>\n      <th>502</th>\n      <td>0.04527</td>\n      <td>0.0</td>\n      <td>11.93</td>\n      <td>0.0</td>\n      <td>0.573</td>\n      <td>6.120</td>\n      <td>76.7</td>\n      <td>2.2875</td>\n      <td>1.0</td>\n      <td>273.0</td>\n      <td>21.0</td>\n      <td>396.90</td>\n      <td>9.08</td>\n    </tr>\n    <tr>\n      <th>503</th>\n      <td>0.06076</td>\n      <td>0.0</td>\n      <td>11.93</td>\n      <td>0.0</td>\n      <td>0.573</td>\n      <td>6.976</td>\n      <td>91.0</td>\n      <td>2.1675</td>\n      <td>1.0</td>\n      <td>273.0</td>\n      <td>21.0</td>\n      <td>396.90</td>\n      <td>5.64</td>\n    </tr>\n    <tr>\n      <th>504</th>\n      <td>0.10959</td>\n      <td>0.0</td>\n      <td>11.93</td>\n      <td>0.0</td>\n      <td>0.573</td>\n      <td>6.794</td>\n      <td>89.3</td>\n      <td>2.3889</td>\n      <td>1.0</td>\n      <td>273.0</td>\n      <td>21.0</td>\n      <td>393.45</td>\n      <td>6.48</td>\n    </tr>\n    <tr>\n      <th>505</th>\n      <td>0.04741</td>\n      <td>0.0</td>\n      <td>11.93</td>\n      <td>0.0</td>\n      <td>0.573</td>\n      <td>6.030</td>\n      <td>80.8</td>\n      <td>2.5050</td>\n      <td>1.0</td>\n      <td>273.0</td>\n      <td>21.0</td>\n      <td>396.90</td>\n      <td>7.88</td>\n    </tr>\n  </tbody>\n</table>\n<p>506 rows × 13 columns</p>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 40
    }
   ],
   "source": [
    "X = pd.DataFrame(data, columns=feature_names)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y = pd.DataFrame(target, columns=['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбиение на тренировочные и тестовые датафреймы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создание модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 46
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.711226005748496"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 49
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Создайте модель под названием model с помощью RandomForestRegressor из модуля.\n",
    "сделайте агрумент n_estimators равным 1000, \n",
    "max_depth должен быть равен 12 и random_state сделайте равным 42.\n",
    "\n",
    "Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression, \n",
    "но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0],\n",
    "чтобы получить из датафрейма одномерный массив Numpy,\n",
    "так как для класса RandomForestRegressor в данном методе для аргумента y предпочтительно \n",
    "применение массивов вместо датафрейма.\n",
    "\n",
    "Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.\n",
    "Напишите в комментариях к коду, какая модель в данном случае работает лучше.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=1000, max_depth=12, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=12,\n                      max_features='auto', max_leaf_nodes=None,\n                      min_impurity_decrease=0.0, min_impurity_split=None,\n                      min_samples_leaf=1, min_samples_split=2,\n                      min_weight_fraction_leaf=0.0, n_estimators=1000,\n                      n_jobs=None, oob_score=False, random_state=42, verbose=0,\n                      warm_start=False)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 52
    }
   ],
   "source": [
    "model.fit(X_train, y_train.values[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.8749965273218174"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 55
    }
   ],
   "source": [
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>* Задание 3</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Вызовите документацию для класса RandomForestRegressor,\n",
    "найдите информацию об атрибуте feature_importances_.\n",
    "\n",
    "С помощью этого атрибута найдите сумму всех показателей важности\n",
    "и установите, какие два признака показывают наибольшую важность.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "? RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.03211748, 0.00154999, 0.0070941 , 0.0011488 , 0.01436832,\n       0.40270459, 0.01424477, 0.06403265, 0.00496762, 0.01169177,\n       0.01808961, 0.0123114 , 0.41567892])"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 57
    }
   ],
   "source": [
    "imps = model.feature_importances_\n",
    "imps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0.9999999999999999"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 58
    }
   ],
   "source": [
    "imps.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "CRIM: 0.03211747801029039\n\nZN: 0.0015499893488862256\n\nINDUS: 0.007094098492215253\n\nCHAS: 0.0011487958307451888\n\nNOX: 0.014368315731541832\n\nRM: 0.402704591696731\n\nAGE: 0.014244766864655404\n\nDIS: 0.06403265381454112\n\nRAD: 0.004967618842627067\n\nTAX: 0.011691768621898036\n\nPTRATIO: 0.018089605464908655\n\nB: 0.012311395829965457\n\nLSTAT: 0.4156789214509943\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for feat, imp in zip(feature_names, imps):\n",
    "    print('{}: {}\\n'.format(feat, imp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самые значимые признаки - RM и LSTAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      ".. _boston_dataset:\n\nBoston house prices dataset\n---------------------------\n\n**Data Set Characteristics:**  \n\n    :Number of Instances: 506 \n\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n\n    :Attribute Information (in order):\n        - CRIM     per capita crime rate by town\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n        - INDUS    proportion of non-retail business acres per town\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n        - NOX      nitric oxides concentration (parts per 10 million)\n        - RM       average number of rooms per dwelling\n        - AGE      proportion of owner-occupied units built prior to 1940\n        - DIS      weighted distances to five Boston employment centres\n        - RAD      index of accessibility to radial highways\n        - TAX      full-value property-tax rate per $10,000\n        - PTRATIO  pupil-teacher ratio by town\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n        - LSTAT    % lower status of the population\n        - MEDV     Median value of owner-occupied homes in $1000's\n\n    :Missing Attribute Values: None\n\n    :Creator: Harrison, D. and Rubinfeld, D.L.\n\nThis is a copy of UCI ML housing dataset.\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n\n\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\nprices and the demand for clean air', J. Environ. Economics & Management,\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\npages 244-261 of the latter.\n\nThe Boston house-price data has been used in many machine learning papers that address regression\nproblems.   \n     \n.. topic:: References\n\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for line in boston.DESCR.split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<h4>* Задание 4</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "В этом задании мы будем работать с датасетом, с которым мы уже \n",
    "знакомы по домашнему заданию по библиотеке Matplotlib, это датасет Credit Card Fraud Detection.\n",
    "\n",
    "Для этого датасета мы будем решать задачу классификации - будем определять, \n",
    "какие из транзакциции по кредитной карте являются мошенническими.\n",
    "\n",
    "Данный датасет сильно несбалансирован (так как случаи мошенничества относительно редки),\n",
    "так что применение метрики accuracy не принесет пользы и не поможет выбрать лучшую модель.\n",
    "Мы будем вычислять AUC, то есть площадь под кривой ROC.\n",
    "\n",
    "Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split.\n",
    "\n",
    "Загрузите датасет creditcard.csv и создайте датафрейм df.\n",
    "С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована.\n",
    "Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков.\n",
    "\n",
    "Примените следующую настройку, чтобы можно было просматритвать все столбцы датафрейма:\n",
    "pd.options.display.max_columns = 100.\n",
    "\n",
    "Просмотрите первые 10 строк датафрейма df.\n",
    "\n",
    "Создайте датафрейм X из датафрейма df, исключив столбец Class.\n",
    "Создайте объект Series под названием y из столбца Class.\n",
    "\n",
    "Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split,\n",
    "используя аргументы: test_size=0.3, random_state=100, stratify=y.\n",
    "У вас должны получиться объекты X_train, X_test, y_train и y_test.\n",
    "Просмотрите информацию о их форме.\n",
    "\n",
    "Для поиска по сетке параметров задайте такие параметры:\n",
    "parameters = [{'n_estimators': [10, 15], \n",
    "               'max_features': np.arange(3, 5),\n",
    "               'max_depth': np.arange(4, 7)}]\n",
    "               \n",
    "Создайте модель GridSearchCV со следующими аргументами:\n",
    "estimator=RandomForestClassifier(random_state=100), \n",
    "param_grid=parameters,\n",
    "scoring='roc_auc',\n",
    "cv=3.\n",
    "    \n",
    "Обучите модель на тренировочном наборе данных (может занять несколько минут).\n",
    "\n",
    "Просмотрите параметры лучшей модели с помощью атрибута best_params_.\n",
    "\n",
    "Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.\n",
    "Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1)\n",
    "и запишите в массив y_pred_proba.\n",
    "\n",
    "Из модуля sklearn.metrics импортируйте метрику roc_auc_score.\n",
    "Вычислите AUC на тестовых данных и сравните с результатом, \n",
    "полученным на тренировочных данных, используя в качестве аргументов\n",
    "массивы y_test и y_pred_proba.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-963e0b056d58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'creditcard.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'creditcard.csv' does not exist: b'creditcard.csv'"
     ],
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'creditcard.csv' does not exist: b'creditcard.csv'",
     "output_type": "error"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df['Class'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "parameters = [{'n_estimators': [10, 15], \n",
    "               'max_features': np.arange(3, 5),\n",
    "               'max_depth': np.arange(4, 7)}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(estimator=RandomForestClassifier(random_state=100), \n",
    "                   param_grid=parameters,\n",
    "                   scoring='roc_auc',\n",
    "                   cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred_proba = clf.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}